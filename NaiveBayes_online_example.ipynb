{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate\n",
    "%matplotlib inline\n",
    "\n",
    "# Intel DAAL related imports\n",
    "from daal.data_management import (\n",
    "    DataSourceIface, FileDataSource, HomogenNumericTable, CSRNumericTable, NumericTable, BlockDescriptor\n",
    ")\n",
    "\n",
    "# Helpersfor getArrayFromNT and printNT. See utils.py\n",
    "from utils import *\n",
    "\n",
    "# Import numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting configurations\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Multinomial Naive Bayes\n",
    "\n",
    "### Tutorial brief\n",
    "This tutorial is an example of using Naive Bayes algorithms from pyDAAL to build predictive models.\n",
    "We use the well-studied 20 Newsgroups dataset to train Multinomial Naive Bayes model in online processing mode. We  test the accuracy of the model using quality metrics for multi-class classification. The code for Multinomial Naive Bayes model training and prediction is provided partially. You are required to fill in the gaps.\n",
    "\n",
    "### Learning objectives\n",
    "* To understand how to process the sparse data that doen not fit into memory using online computing mode. \n",
    "* To understand and practice the typical code sequence of using pyDAAL for classification.\n",
    "* To understand how to measuring the quality of the trained model.\n",
    "\n",
    "\n",
    "### Multinomial Naive Bayes introduction\n",
    "Supervised learning involves training a model using the data that has known responses, and then apply the model to predict responses for unseen data. In the case of **Multinomial Naive Bayes** classifier, the model is probabilistic.\n",
    "\n",
    "Let $J$ be the number of classes, indexed $k = 0, 1, \\ldots, J-1$. The feature vector $x_i = (x_{i1}, \\ldots, x_{ip})$, $i = 1, \\ldots, n$, contains scaled frequencies: the value of $x_{ij}$ is the frequency of the $j$-th feature is observed in the vector $x_i$. In terms of the document classification problem, $x_{ij}$ is the frequency of occurrence of the word indexed $j$ in the document $x_i$.\n",
    "The response $y_i$ is the index of the class, $y_i \\in {0, 1, \\ldots, J-1}$ corresponding to the document $x_i$.\n",
    "\n",
    "On the training stage the probability estimates of the occurense on the word $i$ in the document class $k$ are computed:\n",
    "$$log(\\theta_{ki}) = log\\bigg( \\frac{N_{ki} + \\alpha_k}{N_k + \\alpha}\\bigg)$$\n",
    "where\n",
    "$$N_{ki} = \\sum \\limits_{x: x \\in X, y(x) = k} x_i, N_k = \\sum \\limits_{i = 1}^m N_i$$\n",
    "\n",
    "On the prediction stage, given a new feature vector $x$ , the classifier determines the class the vector belongs to:\n",
    "$$y(x) = argmax_{k \\in \\{0, \\ldots, J-1\\}} \\Big(log(p(y=k)) + \\sum \\limits_{i} log(\\theta_{ki})\\Big)$$\n",
    "\n",
    "The details about the algorithm: [\"Tackling the Poor Assumptions of Naive Bayes Text Classifiers\" by Jason D. M. Rennie et al.](https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Newsgroups dataset\n",
    "The dataset has already been downloaded to the ./mldata folder. There are 11314 training and 7514 testing samples (documents) and 130107 features (words). Here's the detailed information about this dataset, including descriptions of each class:\n",
    "\n",
    "> Origin: \n",
    "\n",
    "> This dataset was collected in the School of Computer Science, Carnegie Mellon University. \n",
    "\n",
    "> Creator: \n",
    "\n",
    "> Tom Mitchell\n",
    "\n",
    "> Data Set Information:\n",
    "\n",
    "> Concerns 18828 messages from 20 newsgroups.\n",
    "\n",
    "> Information about classes:\n",
    "\n",
    "> 1.  alt.atheism\n",
    "> 2.  comp.graphics\n",
    "> 3.  comp.os.ms-windows.misc\n",
    "> 4.  comp.sys.ibm.pc.hardware\n",
    "> 5.  comp.sys.mac.hardware\n",
    "> 6.  comp.windows.x\n",
    "> 7.  misc.forsale\n",
    "> 8.  rec.autos\n",
    "> 9.  rec.motorcycles\n",
    "> 10. rec.sport.baseball\n",
    "> 11. rec.sport.hockey\n",
    "> 12. sci.crypt\n",
    "> 13. sci.electronics\n",
    "> 14. sci.med\n",
    "> 15. sci.space\n",
    "> 16. soc.religion.christian\n",
    "> 17. talk.politics.guns\n",
    "> 18. talk.politics.mideast\n",
    "> 19. talk.politics.misc\n",
    "> 20. talk.religion.misc\n",
    "\n",
    "> Words examples: archive, name, atheism, resources, alt, last, modified, december, version, atheist, addresses, of, organizations, usa, freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sparse numeric table from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSparseTable(file, nFeatures):\n",
    "    rowIdx = []\n",
    "    colIdx = []\n",
    "    data = []\n",
    "    with open(file, 'r') as csvfile:\n",
    "        datareader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in datareader:\n",
    "            rowIdx.append(int(row[0]))\n",
    "            colIdx.append(int(row[1]))\n",
    "            data.append(float(row[2]))\n",
    "\n",
    "    rowIdx = np.array(rowIdx)\n",
    "    rowIdx = rowIdx - rowIdx[0]\n",
    "\n",
    "    nObservations = rowIdx[len(data)-1] + 1\n",
    "    cooData = coo_matrix((data, (rowIdx, colIdx)), shape=(nObservations, nFeatures))\n",
    "    csrDara = cooData.tocsr()\n",
    "    table = CSRNumericTable(csrDara.data.astype(np.float64), csrDara.indices.astype(np.uint64) + 1, csrDara.indptr.astype(np.uint64) + 1,\n",
    "                            int(nFeatures), int(nObservations))\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes model training on 20 Newsgroups dataset\n",
    "The training data is split into 5 blocks, ~2200 samples each. For each block of data the code below does following:\n",
    "- Reads the data in coordinate format from files `/mldata/20newsgroups.coo.<block>.csv` and creates a CSRNumericTable with training data (`xTrain`)\n",
    "- Reads the  ground truth into dense NumericTable (`yTrain`)\n",
    "- Updates the training result with a new block of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "from daal.algorithms import classifier\n",
    "from daal.algorithms.multinomial_naive_bayes import training as nb_training\n",
    "\n",
    "# Number of blocks of data in the training data set\n",
    "nBlocks = 5\n",
    "# Number of classes\n",
    "nClasses = 20\n",
    "# Number of words in the documents\n",
    "nFeatures = 130107\n",
    "\n",
    "# Create an algorithm object to train Multinomial Naive Bayes model in online processing mode\n",
    "nbTrain = nb_training.Online(nClasses, method=nb_training.fastCSR)\n",
    "\n",
    "for i in range(nBlocks):\n",
    "    # Load new block of data from CSV file\n",
    "    xTrain = createSparseTable('./mldata/20newsgroups.coo.' + str(i + 1) + '.csv', nFeatures)\n",
    "    # Load new block of labels from CSV file\n",
    "    labelsDataSource = FileDataSource(\n",
    "        './mldata/20newsgroups.labels.' + str(i + 1) + '.csv',\n",
    "        DataSourceIface.doAllocateNumericTable, DataSourceIface.doDictionaryFromContext\n",
    "    )\n",
    "    labelsDataSource.loadDataBlock()\n",
    "    yTrain = labelsDataSource.getNumericTable()\n",
    "\n",
    "    # Set input\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #\n",
    "    # There are two pieces of input to be set: data and labels. You should\n",
    "    # use the 'input.set' member methods of the nbTrain algorithm object.\n",
    "    # The input IDs to use are 'classifier.training.data' and 'classifier.training.labels'\n",
    "    # respectively.\n",
    "\n",
    "    # Compute\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #\n",
    "    # Call the 'compute()' method of your algorithm object to update the partial model.\n",
    "\n",
    "model = nbTrain.finalizeCompute().get(classifier.training.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with Multinomial Naive Bayes model\n",
    "\n",
    "The code below gets the training data from `sklearn` 20 Newsgroups dataset and creates 2 NumericTables: test data in CSR format (xTest) and test ground truth (yTest). We use Multinomial Naive Bayes prediction algorithm and the model obtained on the training stage to compute the predictions for a new, prevoiusly unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as ds\n",
    "from daal.algorithms.multinomial_naive_bayes import prediction as nb_prediction\n",
    "\n",
    "newsgroups_test = ds.fetch_20newsgroups_vectorized(subset='test')\n",
    "\n",
    "testData = newsgroups_test.data\n",
    "\n",
    "xTest = CSRNumericTable(testData.data.astype(np.float64), testData.indices.astype(np.uint64) + 1, testData.indptr.astype(np.uint64) + 1,\n",
    "                        int(testData.shape[1]), int(testData.shape[0]))\n",
    "yTest = newsgroups_test.target\n",
    "\n",
    "# Create an algorithm object to predict Multinomial Naive Bayes values\n",
    "nbTest = nb_prediction.Batch(nClasses, method=nb_prediction.fastCSR)\n",
    "\n",
    "# Pass a testing data set and the trained model to the algorithm\n",
    "nbTest.input.setTable(classifier.prediction.data,  xTest)\n",
    "nbTest.input.setModel(classifier.prediction.model, model)\n",
    "\n",
    "# Compute\n",
    "predictions = nbTest.compute().get(classifier.prediction.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the confusion matrix\n",
    "To see if the model has done a good job, we print the confusion matrix.\n",
    "\n",
    "|                |           ||            Predicted Class             ||\n",
    "| -------------- | --------- | --------- | --------- | ---- | --------- |\n",
    "|                |           |  ** 1 **  |  ** 2 **  |  ... |  ** J **  |\n",
    "|                |  ** 1 **  |  $n_{11}$ |  $n_{12}$ |  ... |  $n_{1J}$ |\n",
    "|**Actual Class**|  ** 2 **  |  $n_{21}$ |  $n_{22}$ |  ... |  $n_{2J}$ |\n",
    "|                |    ...    |    ...    |    ...    |  ... |    ...    |\n",
    "|                |  ** J **  |  $n_{J1}$ |  $n_{J2}$ |  ... |  $n_{JJ}$ |\n",
    "\n",
    "Here $n_{ij}$ is the number of samples that belong to actual class $i$, and predicted as the class $j$.\n",
    "\n",
    "If the model does a perfect job then the diagonal elements of the matrix will dominate. As we'll see, it's not quite the case. But still the predictions are close to true values in many cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daal.algorithms.multi_class_classifier import quality_metric_set\n",
    "from daal.algorithms.classifier.quality_metric import multiclass_confusion_matrix\n",
    "from daal.data_management import BlockDescriptor, readOnly\n",
    "\n",
    "qualityMetricSet = quality_metric_set.Batch(nClasses)\n",
    "input = qualityMetricSet.getInputDataCollection().getInput(quality_metric_set.confusionMatrix)\n",
    "\n",
    "yTest2d = yTest.reshape(yTest.size, 1)\n",
    "groundTruth = HomogenNumericTable(yTest2d.astype(np.float64))\n",
    "input.set(multiclass_confusion_matrix.predictedLabels,   predictions)\n",
    "input.set(multiclass_confusion_matrix.groundTruthLabels, groundTruth)\n",
    "\n",
    "# Compute quality metrics and get the quality metrics\n",
    "# returns ResultCollection class from daal.algorithms.multi_class_classifier.quality_metric_set\n",
    "qualityMetricResult = qualityMetricSet.compute().getResult(quality_metric_set.confusionMatrix)\n",
    "confusionMatrix = qualityMetricResult.get(multiclass_confusion_matrix.confusionMatrix)\n",
    "\n",
    "bd = BlockDescriptor()\n",
    "nrows = confusionMatrix.getNumberOfRows()\n",
    "confusionMatrix.getBlockOfRows(0, nrows, readOnly, bd)\n",
    "npa = np.copy(bd.getArray())\n",
    "print(npa)\n",
    "confusionMatrix.releaseBlockOfRows(bd)\n",
    "\n",
    "qualityMetricsTable = qualityMetricResult.get(multiclass_confusion_matrix.multiClassMetrics)\n",
    "qualityMetricsTable.getBlockOfRows(0, 1, readOnly, bd)\n",
    "qualityMetricsData = bd.getArray().flatten()\n",
    "print(\"Average accuracy: {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.averageAccuracy]))\n",
    "print(\"Error rate:       {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.errorRate]))\n",
    "print(\"Micro precision:  {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.microPrecision]))\n",
    "print(\"Micro recall:     {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.microRecall]))\n",
    "print(\"Micro F-score:    {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.microFscore]))\n",
    "print(\"Macro precision:  {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.macroPrecision]))\n",
    "print(\"Macro recall:     {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.macroRecall]))\n",
    "print(\"Macro F-score:    {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.macroFscore]))\n",
    "qualityMetricsTable.releaseBlockOfRows(bd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this lab, we learned a widely used algorithm for documents classification: Multinomial Naive Bayes. We saw how to apply it to the 20 Newsgroups dataset. We studied and practiced pyDAAL API for this algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
